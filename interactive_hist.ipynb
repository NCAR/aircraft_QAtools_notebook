{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:25.409271Z",
     "iopub.status.busy": "2024-03-14T19:03:25.409000Z",
     "iopub.status.idle": "2024-03-14T19:03:28.451309Z",
     "shell.execute_reply": "2024-03-14T19:03:28.450975Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from metpy.plots import SkewT\n",
    "from metpy.units import pandas_dataframe_to_unit_arrays, units\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import Title, CustomJS, Select, TextInput, Button, LinearAxis, Range1d, FuncTickFormatter\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.palettes import Category10\n",
    "import warnings\n",
    "import itertools \n",
    "import holoviews as hv \n",
    "from holoviews import dim, opts\n",
    "import hvplot.pandas\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "warnings.filterwarnings('ignore')\n",
    "output_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.452821Z",
     "iopub.status.busy": "2024-03-14T19:03:28.452733Z",
     "iopub.status.idle": "2024-03-14T19:03:28.656008Z",
     "shell.execute_reply": "2024-03-14T19:03:28.655692Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.system('source ~/.bash_profile')\n",
    "    CL = os.environ.get(\"QA_CL\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.657490Z",
     "iopub.status.busy": "2024-03-14T19:03:28.657404Z",
     "iopub.status.idle": "2024-03-14T19:03:28.659843Z",
     "shell.execute_reply": "2024-03-14T19:03:28.659538Z"
    }
   },
   "outputs": [],
   "source": [
    "if CL == 'command_line_mode':\n",
    "    try:\n",
    "        project = os.environ.get('QA_PROJ')\n",
    "        flight = os.environ.get('QA_FLIGHT')\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    try:\n",
    "        #######################################################################\n",
    "        ####### change project and flight below if running interactively ######\n",
    "        #######################################################################\n",
    "        #project = 'wecan'\n",
    "        #flight = 'rf18'\n",
    "        project = 'CGWAVES'\n",
    "        flight = 'tf02'\n",
    "        #######################################################################\n",
    "    except:\n",
    "        pass\n",
    "print('Project: ' + project)\n",
    "print('Flight: ' + flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the DATA_DIR os environment variable to the current working directory if it is not already set\n",
    "if 'DATA_DIR' not in os.environ:\n",
    "    os.environ['DATA_DIR'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.661235Z",
     "iopub.status.busy": "2024-03-14T19:03:28.661144Z",
     "iopub.status.idle": "2024-03-14T19:03:28.667580Z",
     "shell.execute_reply": "2024-03-14T19:03:28.667311Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the user provided project and flight information to build the path and store the data file as an object\n",
    "########################################################################\n",
    "# update filepath based on where the netcdf files are located\n",
    "########################################################################\n",
    "yr = '2024'\n",
    "filepath = os.environ.get('DATA_DIR')+'/'+project +'/'\n",
    "input_file = project + flight + '.nc'\n",
    "nc = netCDF4.Dataset(filepath + input_file, mode='r')\n",
    "\n",
    "# try to get global attributes from the netcdf file if they are present\n",
    "# determine preliminary or final status\n",
    "try:\n",
    "    proc_status = nc.getncattr('WARNING')\n",
    "    print(proc_status)\n",
    "except:\n",
    "    proc_status = 'final'\n",
    "\n",
    "# determine the NIDAS version\n",
    "try:\n",
    "    nidas = nc.getncattr('NIDASrevision')\n",
    "    print('NIDAS version: ' + nidas)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# determine the NIMBUS version\n",
    "try:\n",
    "    nimbus = nc.getncattr('RepositoryRevision')\n",
    "    print('NIMBUS version: ' + nimbus)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# determine the processing date and time\n",
    "try:\n",
    "    proc_date = nc.getncattr('date_created')\n",
    "    print('Processing Date & Time: ' + proc_date)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.668864Z",
     "iopub.status.busy": "2024-03-14T19:03:28.668787Z",
     "iopub.status.idle": "2024-03-14T19:03:28.786470Z",
     "shell.execute_reply": "2024-03-14T19:03:28.786017Z"
    }
   },
   "outputs": [],
   "source": [
    "# sometimes the netcdf4 api produces an issue with big-endian buffer on little-endian compiler\n",
    "byte_swap = False\n",
    "\n",
    "# create empty placeholders for asc, histo_asc and units\n",
    "asc = {}\n",
    "histo_asc = {}\n",
    "units = {}\n",
    "cellsize = {}\n",
    "\n",
    "# use the netcdf4 api to get the netcdf data into a dataframe\n",
    "try:\n",
    "    \n",
    "    # loop over keys in netCDF file and organize\n",
    "    for i in nc.variables.keys():\n",
    "        dims = str(nc.variables[i].dimensions)\n",
    "        \n",
    "        # this if section retrieves data that has time dimension only\n",
    "        # this section retrieves data that has a size distribution dimension in addition to time\n",
    "        if \"sps1\" in dims:\n",
    "            histo_output = nc.variables[i][:, 0, :]\n",
    "            # sometimes the netcdf4 api produces an issue with big-endian buffer on little-endian compiler\n",
    "            if byte_swap == True:\n",
    "                histo_output = histo_output.byteswap().newbyteorder()\n",
    "            else:\n",
    "                pass\n",
    "            histo_asc[i] = pd.DataFrame(histo_output)\n",
    "            \n",
    "            # this try / except block accommodates size distribution data that has an attribute CellSizes\n",
    "            try:\n",
    "                cellsize = nc.variables[i].getncattr('CellSizes')\n",
    "                histo_asc[i].columns = pd.MultiIndex.from_tuples(zip(histo_asc[i].columns, cellsize))\n",
    "            except Exception as e:\n",
    "                histo_asc[i].columns = pd.MultiIndex.from_tuples(zip(histo_asc[i].columns, histo_asc[i].columns))\n",
    "        else:\n",
    "            pass    \n",
    "\n",
    "    \n",
    "    # concatenate the histogram data\n",
    "    histo_asc = pd.concat(histo_asc, axis=1, ignore_index=False)\n",
    "    histo_asc.columns = histo_asc.columns.droplevel(1)\n",
    "    colors = itertools.cycle(Category10[6])\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.788439Z",
     "iopub.status.busy": "2024-03-14T19:03:28.788167Z",
     "iopub.status.idle": "2024-03-14T19:03:28.790298Z",
     "shell.execute_reply": "2024-03-14T19:03:28.790020Z"
    }
   },
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:03:28.791691Z",
     "iopub.status.busy": "2024-03-14T19:03:28.791598Z",
     "iopub.status.idle": "2024-03-14T19:04:39.471777Z",
     "shell.execute_reply": "2024-03-14T19:04:39.471439Z"
    }
   },
   "outputs": [],
   "source": [
    "df = xr.open_dataset(filepath+input_file) #open the dataset as an xarray\n",
    "ds =df.where(df.GGSPD >60, drop = True) #filter the data to not include time on the ground\n",
    "x_width = 1200\n",
    "y_height = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:04:39.473540Z",
     "iopub.status.busy": "2024-03-14T19:04:39.473444Z",
     "iopub.status.idle": "2024-03-14T19:04:39.490460Z",
     "shell.execute_reply": "2024-03-14T19:04:39.490145Z"
    }
   },
   "outputs": [],
   "source": [
    "# create lists of the histogram variables\n",
    "try:\n",
    "    histovar_list = list(histo_asc.columns.levels[0])\n",
    "    histovar_list = [var for var in histovar_list if not var.endswith('VXL')]\n",
    "    histobin_list = []\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# loop over the length of the histogram variable list\n",
    "try:\n",
    "    for i in range(len(histovar_list)):\n",
    "        histobin_list.append(max(list(histo_asc[histovar_list[i]]))+1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# create list of histogram units\n",
    "try:\n",
    "    histo_units = []\n",
    "    for i in histovar_list:\n",
    "        histo_units.append(nc.variables[i].getncattr('units'))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(ds, var, i):\n",
    "    try:\n",
    "        # Check if the variable exists in the dataset\n",
    "        if var not in ds:\n",
    "            print(f\"{var} not in dataset\")\n",
    "            return\n",
    "            \n",
    "        # Get dimensions and check if we have the right ones\n",
    "        dims = ds[var].squeeze().dims\n",
    "\n",
    "        # Find the bin dimension (non-time dimension)\n",
    "        try:\n",
    "            vname = [item for item in dims if 'Time' not in item][0]\n",
    "        except IndexError:\n",
    "            print(f\"{var} doesn't have a non-time dimension for binning\")\n",
    "            return\n",
    "            \n",
    "        # Check if we have any valid data\n",
    "        if ds[var].isnull().all():\n",
    "            print(f\"{var} contains only NaN values - skipping plot\")\n",
    "            return\n",
    "            \n",
    "        # Get plot limits with safety checks\n",
    "        max_z = float(ds[var].to_numpy().max())\n",
    "        if not np.isfinite(max_z) or max_z <= 0:\n",
    "            # Try to find any non-NaN values to plot\n",
    "            non_nan_data = ds[var].where(~np.isnan(ds[var]))\n",
    "            if non_nan_data.count() > 0:\n",
    "                max_z = float(non_nan_data.max().values)\n",
    "                print(f\"Adjusted {var} to use non-NaN maximum: {max_z}\")\n",
    "            else:\n",
    "                print(f\"{var} has invalid maximum value: {max_z} - skipping plot\")\n",
    "                return\n",
    "            \n",
    "        min_y = 1 if ds[var][vname][0] == 0 else float(ds[var][vname][0])\n",
    "        if min_y <= 0:\n",
    "            min_y = 1  # Ensure positive for log scale\n",
    "            \n",
    "        # Set up plot labels\n",
    "        ylab = \"Bin [#]\" if min_y == 1 else \"Cell Size [um]\"\n",
    "        \n",
    "        # Create plot with safe options - replace NaN with 0\n",
    "        plot_ds = ds[var].squeeze().fillna(0).assign_coords({vname: ds[vname]})\n",
    "        \n",
    "        heatmap = plot_ds.hvplot.quadmesh(\n",
    "            cmap='gist_ncar', x='Time', width=x_width, height=y_height,\n",
    "            ylabel=ylab, xlabel='Time [UTC]', \n",
    "            title=f\"{var} Units: {histo_units[i]}\",\n",
    "            y=vname, clim=(0, max_z), ylim=(min_y, None), logy=True,\n",
    "        )\n",
    "        \n",
    "        # Render and show the plot\n",
    "        bokeh_plot = hv.render(heatmap)\n",
    "        show(bokeh_plot)\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f\"{var} does not have vector dimension\")\n",
    "    except KeyError:\n",
    "        print(f\"{var} not in file\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting {var}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T19:04:39.496269Z",
     "iopub.status.busy": "2024-03-14T19:04:39.496185Z",
     "iopub.status.idle": "2024-03-14T19:05:38.253962Z",
     "shell.execute_reply": "2024-03-14T19:05:38.253593Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, var in enumerate(histovar_list):\n",
    "    plot_histogram(ds,var,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qatools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
